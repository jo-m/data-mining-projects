#!/local/anaconda/bin/python
# IMPORTANT: leave the above line as is.

import sys
import numpy as np
import itertools
from sklearn.svm import LinearSVC
from sklearn.linear_model import SGDClassifier
from sklearn.kernel_approximation import RBFSampler, Nystroem
from sklearn.decomposition import PCA

pycharm_mode = False
N_FEATURES = 400  # Dimension of the original data.
CLASSES = (-1, +1)   # The classes that we are trying to predict.
BATCH_SIZE = 5000

feature_map = RBFSampler(gamma=1, random_state=1, n_components=1600)
#feature_map = Nystroem(gamma=1, random_state=1, n_components=1000)
feature_map.fit(np.zeros(N_FEATURES).ravel())

mean = np.array([ 0.00212162,  0.00326179,  0.00336834,  0.00174799,  0.00349184,
        0.00364084,  0.00191759,  0.0021769 ,  0.00187618,  0.00345837,
        0.00525868,  0.00451932,  0.00354109,  0.00304195,  0.00223719,
        0.0017874 ,  0.00216056,  0.00380389,  0.00257312,  0.00291176,
        0.00603775,  0.00235903,  0.00438539,  0.00718921,  0.00369796,
        0.00057401,  0.00302749,  0.00627055,  0.00184411,  0.00182562,
        0.00328554,  0.00350478,  0.00246417,  0.00262952,  0.00358904,
        0.00305671,  0.0021367 ,  0.0012393 ,  0.00212043,  0.00302733,
        0.00158225,  0.01253115,  0.00252808,  0.00526082,  0.0026493 ,
        0.00283104,  0.00391582,  0.00207229,  0.00309384,  0.0020231 ,
        0.00407934,  0.00184451,  0.00317542,  0.00350376,  0.00412888,
        0.00347007,  0.00070272,  0.00129218,  0.00236515,  0.00394606,
        0.00243528,  0.0121647 ,  0.00125262,  0.00269277,  0.00431983,
        0.00064661,  0.00222206,  0.00081016,  0.00276921,  0.00119478,
        0.00332508,  0.00338119,  0.00265463,  0.0009674 ,  0.0021834 ,
        0.00262124,  0.00155939,  0.00303142,  0.00409918,  0.00275503,
        0.00078758,  0.00260581,  0.00271427,  0.00279682,  0.00187073,
        0.00239262,  0.00320792,  0.0028906 ,  0.00125441,  0.00220785,
        0.00217394,  0.00226935,  0.00368206,  0.00280267,  0.00057387,
        0.00308916,  0.00280732,  0.00131975,  0.00075538,  0.00360904,
        0.00328516,  0.00232873,  0.00318097,  0.0038685 ,  0.00269755,
        0.00096894,  0.00231156,  0.00137366,  0.00462414,  0.00385086,
        0.00042486,  0.00152105,  0.00247847,  0.00180765,  0.00283519,
        0.00055578,  0.0041711 ,  0.00229286,  0.00360301,  0.00195783,
        0.00222583,  0.00212151,  0.00140187,  0.00605107,  0.00210259,
        0.00231028,  0.00121161,  0.00297589,  0.00230402,  0.00086444,
        0.00354587,  0.00226539,  0.00370163,  0.00272233,  0.00196373,
        0.00207562,  0.0014668 ,  0.00016834,  0.002242  ,  0.00352347,
        0.00305471,  0.00237915,  0.00042213,  0.00300091,  0.0037222 ,
        0.00242145,  0.00085707,  0.0011148 ,  0.00280439,  0.00137053,
        0.00429162,  0.00321777,  0.00256721,  0.00234682,  0.002131  ,
        0.00291648,  0.00169934,  0.00282906,  0.00305243,  0.00319355,
        0.00415848,  0.00056474,  0.00302456,  0.00028568,  0.00259158,
        0.00198337,  0.00266347,  0.00018718,  0.00231861,  0.00191726,
        0.00357625,  0.00303815,  0.00059133,  0.00112872,  0.00360599,
        0.0009617 ,  0.0018684 ,  0.00284999,  0.00402857,  0.00041874,
        0.00088446,  0.0027902 ,  0.00216078,  0.00321767,  0.00128265,
        0.00116274,  0.00245032,  0.00239802,  0.0035837 ,  0.00316619,
        0.00533856,  0.00319106,  0.00301703,  0.00024908,  0.00229317,
        0.00229822,  0.00413878,  0.00236707,  0.00481001,  0.00051182,
        0.00093661,  0.00036205,  0.00078229,  0.00073511,  0.00282736,
        0.00357597,  0.00574424,  0.00318693,  0.00141272,  0.00404052,
        0.00274451,  0.00228859,  0.00130957,  0.00309494,  0.00147794,
        0.00190639,  0.002389  ,  0.00258242,  0.00188784,  0.00225958,
        0.00419633,  0.00237109,  0.0022675 ,  0.00295178,  0.00079394,
        0.00017189,  0.00070977,  0.00220295,  0.00234809,  0.00034055,
        0.00301383,  0.00407604,  0.00180029,  0.00454906,  0.00255933,
        0.00217492,  0.00310283,  0.00136812,  0.00111818,  0.00354753,
        0.00251557,  0.00428833,  0.00089241,  0.00152644,  0.00042644,
        0.00205363,  0.00297503,  0.00059229,  0.00059631,  0.00549811,
        0.0006014 ,  0.00240224,  0.00515927,  0.00322231,  0.00167304,
        0.00243306,  0.00331631,  0.00181181,  0.00035641,  0.00229916,
        0.00421608,  0.00334903,  0.00411833,  0.00090727,  0.00277125,
        0.00209058,  0.00223081,  0.00215712,  0.00337334,  0.00256689,
        0.00420658,  0.00237474,  0.00129659,  0.00384876,  0.00216036,
        0.00325664,  0.00250349,  0.00393242,  0.00320601,  0.00354736,
        0.00227792,  0.00209326,  0.00127987,  0.00294757,  0.00302354,
        0.00315968,  0.00073388,  0.00230418,  0.0032597 ,  0.00283095,
        0.00338295,  0.00214611,  0.00136387,  0.00254704,  0.0004655 ,
        0.00141908,  0.00177637,  0.00041698,  0.00072532,  0.00303326,
        0.00139852,  0.00247852,  0.00024122,  0.00435185,  0.00451566,
        0.00473464,  0.00101374,  0.00277306,  0.0029008 ,  0.00248995,
        0.00178907,  0.00279824,  0.00079932,  0.0014155 ,  0.0018548 ,
        0.00184891,  0.00274162,  0.00316187,  0.00193429,  0.00176305,
        0.00289257,  0.00051294,  0.00412763,  0.0013291 ,  0.00251302,
        0.0032104 ,  0.00159126,  0.00331987,  0.0032341 ,  0.00160798,
        0.00040634,  0.00159926,  0.00139622,  0.00221778,  0.00293532,
        0.00286631,  0.00125551,  0.00282113,  0.00017817,  0.00146276,
        0.00259542,  0.00363618,  0.00283081,  0.0032123 ,  0.00092807,
        0.00229373,  0.0031122 ,  0.00882636,  0.00197553,  0.00160297,
        0.00306386,  0.00175019,  0.00254783,  0.00140688,  0.00050722,
        0.00241842,  0.00165606,  0.00141604,  0.0025945 ,  0.00155229,
        0.00194766,  0.00437964,  0.00248807,  0.00248519,  0.00325458,
        0.00081752,  0.00047388,  0.00262356,  0.0029982 ,  0.00334169,
        0.00304983,  0.00322412,  0.00256105,  0.00744244,  0.00262826,
        0.00103592,  0.00185371,  0.00320022,  0.00254778,  0.00109616,
        0.00165507,  0.00226171,  0.00063538,  0.00267484,  0.00114717,
        0.00207612,  0.00062648,  0.00129359,  0.00306327,  0.00132358,
        0.00173316,  0.00279363,  0.00462749,  0.00153636,  0.00267826,
        0.0021034 ,  0.00322769,  0.00029217,  0.00115241,  0.00318764])

std = np.array([
    0.0019651 ,  0.00359108,  0.00361392,  0.00226144,  0.00437216,
    0.00809089,  0.0035457 ,  0.0017938 ,  0.00255635,  0.00340048,
    0.00523634,  0.00384221,  0.00590808,  0.00261679,  0.00265207,
    0.00256694,  0.00193937,  0.00377001,  0.00305155,  0.0025441 ,
    0.03529837,  0.00222906,  0.00358607,  0.00854748,  0.00308801,
    0.00197418,  0.00655728,  0.01057583,  0.00161546,  0.0018134 ,
    0.00343799,  0.00733534,  0.00190563,  0.00208337,  0.00402314,
    0.00293276,  0.00207797,  0.0020883 ,  0.00239697,  0.00511364,
    0.00518177,  0.01394437,  0.00228593,  0.0059401 ,  0.00236377,
    0.00223947,  0.00484597,  0.00188813,  0.00223356,  0.00166747,
    0.00339757,  0.00216911,  0.00287038,  0.00411146,  0.00428038,
    0.0039807 ,  0.00099181,  0.00202116,  0.00224811,  0.0028622 ,
    0.00249606,  0.01447428,  0.0015557 ,  0.00321965,  0.00400802,
    0.00115748,  0.00198775,  0.00199008,  0.00213502,  0.00149223,
    0.00382068,  0.00351666,  0.00430395,  0.00127523,  0.00193354,
    0.00255585,  0.00281865,  0.00312554,  0.0037943 ,  0.00244198,
    0.00134278,  0.0033438 ,  0.00235225,  0.00228877,  0.00162203,
    0.00222208,  0.00364224,  0.00225836,  0.00149148,  0.00188687,
    0.00202189,  0.00185455,  0.00352052,  0.00350613,  0.00115395,
    0.00400201,  0.00226013,  0.0019471 ,  0.00208933,  0.00369025,
    0.00287029,  0.00231873,  0.00278119,  0.00511463,  0.00214197,
    0.0018466 ,  0.00205616,  0.00238265,  0.00652857,  0.00426735,
    0.00129169,  0.00298933,  0.0019741 ,  0.00172793,  0.00265909,
    0.00180498,  0.00309094,  0.00299399,  0.00405293,  0.00275067,
    0.00254224,  0.00213746,  0.00206818,  0.01000646,  0.00196992,
    0.00179789,  0.00166733,  0.00373593,  0.00207152,  0.00115465,
    0.00351164,  0.0021284 ,  0.00717977,  0.00212871,  0.00197541,
    0.00189964,  0.00155462,  0.00095148,  0.00236962,  0.00377723,
    0.00262407,  0.00284373,  0.00110279,  0.00235398,  0.00329553,
    0.00230759,  0.0012548 ,  0.0020122 ,  0.00345451,  0.00178997,
    0.00603381,  0.00366651,  0.00274489,  0.00228842,  0.00198019,
    0.00225974,  0.00281179,  0.00261756,  0.00291835,  0.00460246,
    0.0045396 ,  0.00204216,  0.00267568,  0.00087908,  0.00320374,
    0.00208124,  0.00212866,  0.00110929,  0.00277914,  0.00214359,
    0.00707323,  0.0024059 ,  0.00125362,  0.00247641,  0.00391649,
    0.00147887,  0.00204096,  0.00225098,  0.00444606,  0.00140817,
    0.00175533,  0.00254202,  0.00368611,  0.00640495,  0.00195887,
    0.00199935,  0.00283142,  0.00217462,  0.00293477,  0.00282668,
    0.00536411,  0.00362485,  0.0025733 ,  0.00121978,  0.00199366,
    0.00195807,  0.00598643,  0.00247674,  0.00605076,  0.00189049,
    0.00145685,  0.00103628,  0.0024339 ,  0.00138629,  0.00224056,
    0.0038007 ,  0.00697584,  0.00311568,  0.00140794,  0.00500049,
    0.00255092,  0.00195665,  0.00223856,  0.00330602,  0.00159639,
    0.00279365,  0.00284216,  0.00206951,  0.00225057,  0.00273308,
    0.00303247,  0.00218575,  0.00237279,  0.00230588,  0.00112447,
    0.00102819,  0.00202161,  0.00200168,  0.0020904 ,  0.00119014,
    0.00228974,  0.00566594,  0.00171169,  0.00565289,  0.00208057,
    0.00205117,  0.00232131,  0.00137606,  0.00204085,  0.00263155,
    0.0026806 ,  0.00497191,  0.00239636,  0.00190742,  0.00107856,
    0.00197298,  0.00363131,  0.00116659,  0.00132491,  0.01279113,
    0.00118965,  0.0026879 ,  0.00521349,  0.0023379 ,  0.00245965,
    0.00237858,  0.00656191,  0.0035433 ,  0.00102833,  0.00201884,
    0.00541628,  0.0030879 ,  0.00457847,  0.00122828,  0.00458019,
    0.00170542,  0.0020323 ,  0.00199614,  0.00322493,  0.00342348,
    0.00459081,  0.00219012,  0.00157252,  0.00491132,  0.00243567,
    0.00266373,  0.00296419,  0.00533173,  0.00256084,  0.00381353,
    0.00201053,  0.00279847,  0.00133359,  0.00487749,  0.00245085,
    0.00542545,  0.00211871,  0.00206301,  0.00351246,  0.00237668,
    0.00350095,  0.0027646 ,  0.00205237,  0.00208105,  0.00118262,
    0.00149172,  0.00159871,  0.0012261 ,  0.00109057,  0.00298107,
    0.00134228,  0.00298797,  0.00120362,  0.0055727 ,  0.00537029,
    0.00403907,  0.00148292,  0.00301837,  0.00358804,  0.00236102,
    0.00180055,  0.0027682 ,  0.00120302,  0.00135833,  0.00177119,
    0.00206034,  0.00261389,  0.00270606,  0.00215055,  0.00201163,
    0.00369875,  0.00122329,  0.00606611,  0.00218476,  0.00209084,
    0.00416253,  0.0023233 ,  0.00293427,  0.00321548,  0.00209159,
    0.00162542,  0.00158339,  0.00246903,  0.00190546,  0.0023443 ,
    0.00406351,  0.00191533,  0.00271678,  0.00102083,  0.00256648,
    0.00204324,  0.00387997,  0.00280869,  0.00257221,  0.00151447,
    0.00262602,  0.00248473,  0.02322805,  0.0016678 ,  0.00228526,
    0.00307744,  0.00181588,  0.00227394,  0.00212493,  0.00165419,
    0.00227213,  0.00145137,  0.00257472,  0.00249991,  0.00464421,
    0.00201625,  0.00557147,  0.00375217,  0.00420005,  0.00422139,
    0.00120469,  0.0010383 ,  0.00325025,  0.00269193,  0.00292216,
    0.00356827,  0.00334817,  0.00207048,  0.00607222,  0.00331917,
    0.00123998,  0.00166531,  0.00267983,  0.00225379,  0.00164128,
    0.00171111,  0.00188794,  0.00115888,  0.00228212,  0.00151007,
    0.00203666,  0.001353  ,  0.00251542,  0.00263632,  0.00160865,
    0.00209168,  0.0024548 ,  0.00697243,  0.00167912,  0.00218669,
    0.00180191,  0.00306884,  0.00091363,  0.00160963,  0.00247535])

def transform(x_original):
    features = x_original.reshape((1, 400L))
    features = features - mean
    #features = features / std
    kernel_approx = feature_map.transform(features)
    features = np.concatenate((4*features, kernel_approx), axis=1)
    return features

def lines(source):
    for line in source:
        line = line.strip()
        (label, x_string) = line.split(" ", 1)
        label = int(label)
        x_original = np.fromstring(x_string, sep=' ')
        yield label, transform(x_original)

def main():
    if pycharm_mode:
        import argparse
        parser = argparse.ArgumentParser()
        parser.add_argument("--input", help="The filename to be processed", required=True)
        parser.add_argument("--output", help="The filename to be written to")
        args = parser.parse_args()
        if args.input:
            input_f = open(args.input)
            input = lines(input_f)

        if args.output:
            output = args.output
        else:
            output = sys.stdout
    else:
        input = lines(sys.stdin)
        output = sys.stdout

    while True:
        m = list(itertools.islice(input, 0, BATCH_SIZE))
        if len(m) == 0:
            break
        X = np.vstack([x[1] for x in m])
        Y = np.array([x[0] for x in m]).T

        clf = LinearSVC(
            fit_intercept=False,
            loss='hinge',
            C=100000
        )
        # clf = SGDClassifier(
        #     fit_intercept=False,
        #     loss='hinge',
        #     alpha=0.000001,
        #     n_iter=200
        # )
        clf.fit(X, Y)
        np.savetxt(output, clf.coef_)

    if pycharm_mode:
        input_f.close()

if __name__ == '__main__':
    main()
